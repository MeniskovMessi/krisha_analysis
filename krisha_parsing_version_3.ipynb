{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1005b1e0-4f46-4cd4-8a0d-91ab64bb23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f733353-f5bc-4cc5-a912-43e022837428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c5f021-37cd-42a5-ac80-e49b787cbcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import sleep\n",
    "import clickhouse_connect\n",
    "\n",
    "client = clickhouse_connect.get_client(\n",
    "    host='localhost',       \n",
    "    port=8123,              \n",
    "    username='default',     \n",
    "    password='',            \n",
    "    database='krisha'      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "671c00e2-7663-4305-b33f-b806fe7115be",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_keys=[\"price\", \"room_size\",'year_built','apartment_floor','total_floor_of_house']\n",
    "floats=[\"square_meters\",  'kitchen_meters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89520f2a-95ca-4528-abc9-3dbc6da004bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    for row in data:\n",
    "        for key in numerical_keys:\n",
    "            try:\n",
    "                row[key] = int(row[key]) if row.get(key) is not None else 0.0\n",
    "            except (ValueError, TypeError):\n",
    "                row[key] = 0\n",
    "        for key in floats:\n",
    "            try:\n",
    "                row[key] = float(row[key]) if row.get(key) is not None else 0.0\n",
    "            except (ValueError, TypeError):\n",
    "                row[key] = 0.0\n",
    "    \n",
    "    # for i, row in enumerate(data):\n",
    "    #     print(f\"\\nRow {i + 1}\")\n",
    "    #     for key, value in row.items():\n",
    "    #         print(f\"  {key}: {value} ({type(value).__name__})\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "804c4bb3-2a06-4547-925a-50aeb409bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = ({'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf2da42-92e0-42db-95a2-336110b8ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apartment_links(page_html):\n",
    "    soup = BeautifulSoup(page_html, \"html.parser\")\n",
    "    links = []\n",
    "    for a in soup.select(\"a.a-card__title\"):  # CSS selector for listing titles\n",
    "        href = a.get(\"href\")\n",
    "        if href:\n",
    "            links.append(\"https://krisha.kz\" + href)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973520bb-d43d-49a0-bef4-853b4c29fc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_apartment_data(detail_html):\n",
    "    soup = BeautifulSoup(detail_html, \"html.parser\")\n",
    "\n",
    "    # --- Price ---\n",
    "    price_container = soup.find(\"div\", class_=\"offer__price\") or soup.find(\"p\", class_=\"offer__price\")\n",
    "    if price_container:\n",
    "        for span in price_container.find_all(\"span\"):\n",
    "            span.decompose()\n",
    "        raw_price = price_container.get_text(strip=True)\n",
    "        price = re.sub(r\"[^\\d]\", \"\", raw_price)\n",
    "    else:\n",
    "        price = None\n",
    "\n",
    "    # --- Address ---\n",
    "    address = soup.find(\"div\", attrs={\"class\" : 'offer__location offer__advert-short-info'})\n",
    "    address = address.find(\"span\").get_text(strip=True) if address and address.find(\"span\") else None\n",
    "\n",
    "    # --- Split Address ---\n",
    "    city, province = None, None\n",
    "    if address and \",\" in address:\n",
    "        parts = address.split(\",\", 1)\n",
    "        city = parts[0].strip()\n",
    "        province = parts[1].strip()\n",
    "    elif address:\n",
    "        city = address.strip()\n",
    "\n",
    "    # --- Room Size (from h1) ---\n",
    "    room_title = soup.find(\"div\", class_=\"offer__advert-title\")\n",
    "    if room_title:\n",
    "        h1 = room_title.find(\"h1\")\n",
    "        if h1:\n",
    "            text = h1.get_text(strip=True)\n",
    "            room_match = re.search(r\"(\\d+)\", text)\n",
    "            room_size = room_match.group(1) if room_match else None\n",
    "        else:\n",
    "            room_size = None\n",
    "    else:\n",
    "        room_size = None\n",
    "\n",
    "    # --- Square Meters & Kitchen Meters ---\n",
    "    raw_area = None\n",
    "    square_meters = None\n",
    "    kitchen_meters = None\n",
    "    square_container = soup.find(\"div\", attrs={\"data-name\": \"live.square\"})\n",
    "    if square_container:\n",
    "        info = square_container.find(\"div\", class_=\"offer__advert-short-info\")\n",
    "        if info:\n",
    "            raw_area = info.get_text(strip=True)\n",
    "            total_match = re.search(r\"(\\d+\\.?\\d*)\\s*Ğ¼Â²\", raw_area)\n",
    "            kitchen_match = re.search(r\"ĞŸĞ»Ğ¾Ñ‰Ğ°Ğ´ÑŒ ĞºÑƒÑ…Ğ½Ğ¸\\s*â€”\\s*(\\d+\\.?\\d*)\", raw_area)\n",
    "            if total_match:\n",
    "                square_meters = total_match.group(1)\n",
    "            if kitchen_match:\n",
    "                kitchen_meters = kitchen_match.group(1)\n",
    "\n",
    "    # --- Helpers ---\n",
    "    def safe_extract(selector):\n",
    "        container = soup.find(\"div\", attrs={\"data-name\": selector})\n",
    "        if container:\n",
    "            info = container.find(\"div\", class_=\"offer__advert-short-info\")\n",
    "            if info:\n",
    "                return info.get_text(strip=True)\n",
    "        return None\n",
    "\n",
    "    def safe_extract_text_from_a(selector):\n",
    "        container = soup.find(\"div\", attrs={\"data-name\": selector})\n",
    "        if container:\n",
    "            a_tag = container.find(\"a\")\n",
    "            if a_tag:\n",
    "                return a_tag.get_text(strip=True)\n",
    "        return None\n",
    "\n",
    "    def safe_find_text_by_class(class_name):\n",
    "        element = soup.find(\"div\", class_=class_name)\n",
    "        return element.get_text(strip=True) if element else None\n",
    "\n",
    "    def safe_dt_dd(name):\n",
    "        dt = soup.find(\"dt\", attrs={\"data-name\": name})\n",
    "        if dt:\n",
    "            dd = dt.find(\"dd\")\n",
    "            if dd:\n",
    "                return dd.get_text(strip=True)\n",
    "        return None\n",
    "\n",
    "    # --- Custom Fields ---\n",
    "    year_built = safe_extract(\"house.year\")\n",
    "    house_type = safe_extract(\"flat.building\")\n",
    "    complex_name = safe_extract_text_from_a(\"map.complex\")\n",
    "    toilet_type = safe_extract(\"flat.toilet\")\n",
    "    floor_raw = safe_extract(\"flat.floor\")\n",
    "    parking = safe_extract(\"flat.parking\")\n",
    "    mortgaged = safe_find_text_by_class(\"offer__parameters-mortgaged\")\n",
    "    ceiling_height = safe_dt_dd(\"ceiling\")\n",
    "\n",
    "    # --- Split Floor ---\n",
    "    apartment_floor, total_floor_of_house = None, None\n",
    "    if floor_raw:\n",
    "        match = re.search(r\"(\\d+)\\s+Ğ¸Ğ·\\s+(\\d+)\", floor_raw)\n",
    "        if match:\n",
    "            apartment_floor = int(match.group(1))\n",
    "            total_floor_of_house = int(match.group(2))\n",
    "\n",
    "    # --- Return Result ---\n",
    "    return {\n",
    "        \"price\": price,\n",
    "        \"city\": city,\n",
    "        \"province\": province,\n",
    "        \"room_size\": room_size,\n",
    "        \"square_meters\": square_meters,\n",
    "        \"kitchen_meters\": kitchen_meters,\n",
    "        \"year_built\": year_built,\n",
    "        \"house_type\": house_type,\n",
    "        \"complex_name\": complex_name,\n",
    "        \"toilet_type\": toilet_type,\n",
    "        \"apartment_floor\": apartment_floor,\n",
    "        \"total_floor_of_house\": total_floor_of_house,\n",
    "        \"parking\": parking,\n",
    "        \"mortgaged\": mortgaged,\n",
    "        \"ceiling_height\": ceiling_height,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd1a569d-575b-494c-822d-acbcb2170dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_apartments(base_url, max_pages=5, delay=1):\n",
    "    all_data = []\n",
    "\n",
    "    for page in range(1, max_pages + 1):\n",
    "        url = f\"{base_url}?page={page}\"\n",
    "        print(f\"Fetching listings from: {url}\")\n",
    "        response = requests.get(url)\n",
    "        if not response.ok:\n",
    "            print(f\"Failed to fetch page {page}\")\n",
    "            break\n",
    "\n",
    "        links = get_apartment_links(response.text)\n",
    "\n",
    "        for link in links:\n",
    "            print(f\" â†’ Parsing: {link}\")\n",
    "            detail_resp = requests.get(link)\n",
    "            if detail_resp.ok:\n",
    "                data = extract_apartment_data(detail_resp.text)\n",
    "                data[\"url\"] = link\n",
    "                all_data.append(data)\n",
    "            else:\n",
    "                print(f\"   âœ— Failed to load: {link}\")\n",
    "            sleep(delay)  # to avoid getting blocked\n",
    "\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ab8a415-8a7d-4844-b429-dde84f929ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url = \"https://krisha.kz/prodazha/kvartiry/astana/\"\n",
    "# data = scrape_all_apartments(base_url, max_pages=1)\n",
    "# data = convert(data)\n",
    "# df = pd.json_normalize(data)\n",
    "# for col in df.select_dtypes(include='object').columns:\n",
    "#     df[col] = df[col].fillna('')\n",
    "# df\n",
    "# client.insert_df('krisha_apartments', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b71528e-f81d-4e1c-8679-7379acea9508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(base_url, max_pages):\n",
    "    data = scrape_all_apartments(base_url, max_pages=max_pages)\n",
    "\n",
    "    existing_urls = set(\n",
    "        row[0] for row in client.query(\"SELECT url FROM krisha_apartments\").result_rows\n",
    "    )\n",
    "\n",
    "    # data = [row for row in data if row.get(\"url\") not in existing_urls]\n",
    "    \n",
    "    data = convert(data)\n",
    "    df = pd.json_normalize(data)\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].fillna('')\n",
    "\n",
    "    \n",
    "    if not df.empty:\n",
    "        client.insert_df('krisha_apartments', df)\n",
    "        print(f\"âœ… Inserted {len(df)} new rows\")\n",
    "    else:\n",
    "        print(\"âš ï¸ No new rows to insert\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a04aab7-020b-465f-ab7f-dedc758190dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2ebe619-1bef-450a-bf5b-edf8abc7f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(base_url, max_pages):\n",
    "    existing_urls = set(\n",
    "        row[0] for row in client.query(\"SELECT url FROM krisha_apartments\").result_rows\n",
    "    )\n",
    "\n",
    "    inserted_total = 0\n",
    "\n",
    "    for page in range(207, max_pages + 1):\n",
    "        print(f\"ğŸ“„ Processing page {page}...\")\n",
    "        url = f\"{base_url}?page={page}\"\n",
    "        data = scrape_all_apartments(url, max_pages=1)  # force it to scrape only this one page\n",
    "\n",
    "        # Filter out existing URLs\n",
    "        data = [row for row in data if row.get(\"url\") not in existing_urls]\n",
    "\n",
    "        if not data:\n",
    "            print(\"âš ï¸ No new listings on this page.\")\n",
    "            continue\n",
    "\n",
    "        # Convert types\n",
    "        data = convert(data)\n",
    "\n",
    "        # Normalize to DataFrame\n",
    "        df = pd.json_normalize(data)\n",
    "\n",
    "        # Fill empty strings in string columns\n",
    "        for col in df.select_dtypes(include='object').columns:\n",
    "            df[col] = df[col].fillna('')\n",
    "\n",
    "        # Insert into ClickHouse\n",
    "        if not df.empty:\n",
    "            client.insert_df('krisha_apartments', df)\n",
    "            inserted_total += len(df)\n",
    "            clear_output(wait=True)\n",
    "            print(f\"âœ… Inserted {len(df)} rows from page {page}\")\n",
    "\n",
    "            # Update existing_urls set to avoid future duplicates in this run\n",
    "            existing_urls.update(df['url'].tolist())\n",
    "        else:\n",
    "            print(f\"âš ï¸ No rows to insert from page {page}\")\n",
    "\n",
    "    print(f\"\\nğŸš€ Done! Inserted a total of {inserted_total} new rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad3e1a58-2c90-4f20-a518-a8daf9931c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Processing page 207...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=207?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 208...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=208?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 209...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=209?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 210...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=210?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 211...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=211?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 212...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=212?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 213...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=213?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 214...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=214?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 215...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=215?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 216...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=216?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 217...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=217?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 218...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=218?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 219...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=219?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 220...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=220?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 221...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=221?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 222...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=222?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 223...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=223?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 224...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=224?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 225...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=225?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 226...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=226?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 227...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=227?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 228...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=228?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 229...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=229?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 230...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=230?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 231...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=231?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 232...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=232?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 233...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=233?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 234...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=234?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 235...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=235?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 236...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=236?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 237...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=237?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 238...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=238?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 239...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=239?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 240...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=240?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 241...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=241?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 242...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=242?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 243...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=243?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 244...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=244?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 245...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=245?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 246...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=246?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 247...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=247?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 248...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=248?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 249...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=249?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 250...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=250?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 251...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=251?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 252...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=252?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 253...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=253?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 254...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=254?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 255...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=255?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 256...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=256?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 257...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=257?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 258...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=258?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 259...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=259?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 260...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=260?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 261...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=261?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 262...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=262?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 263...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=263?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 264...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=264?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 265...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=265?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 266...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=266?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 267...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=267?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 268...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=268?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 269...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=269?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 270...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=270?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 271...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=271?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 272...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=272?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 273...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=273?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 274...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=274?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 275...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=275?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 276...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=276?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 277...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=277?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 278...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=278?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 279...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=279?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 280...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=280?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 281...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=281?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 282...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=282?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 283...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=283?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 284...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=284?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 285...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=285?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 286...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=286?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 287...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=287?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 288...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=288?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 289...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=289?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 290...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=290?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 291...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=291?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 292...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=292?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 293...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=293?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 294...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=294?page=1\n",
      "âš ï¸ No new listings on this page.\n",
      "ğŸ“„ Processing page 295...\n",
      "Fetching listings from: https://krisha.kz/prodazha/kvartiry/astana/?page=295?page=1\n"
     ]
    },
    {
     "ename": "ConnectTimeout",
     "evalue": "HTTPSConnectionPool(host='krisha.kz', port=443): Max retries exceeded with url: /prodazha/kvartiry/astana/?page=295?page=1 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DE07AFEC00>, 'Connection to krisha.kz timed out. (connect timeout=None)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] ĞŸĞ¾Ğ¿Ñ‹Ñ‚ĞºĞ° ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ±Ñ‹Ğ»Ğ° Ğ±ĞµĞ·ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾Ğ¹, Ñ‚.Ğº. Ğ¾Ñ‚ Ğ´Ñ€ÑƒĞ³Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ° Ğ·Ğ° Ñ‚Ñ€ĞµĞ±ÑƒĞµĞ¼Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ Ğ½Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚ĞºĞ»Ğ¸Ğº, Ğ¸Ğ»Ğ¸ Ğ±Ñ‹Ğ»Ğ¾ Ñ€Ğ°Ğ·Ğ¾Ñ€Ğ²Ğ°Ğ½Ğ¾ ÑƒĞ¶Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ğ¾Ğµ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ¸Ğ·-Ğ·Ğ° Ğ½ĞµĞ²ĞµÑ€Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚ĞºĞ»Ğ¸ĞºĞ° ÑƒĞ¶Ğµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ°",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:716\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    717\u001b[0m     conn,\n\u001b[0;32m    718\u001b[0m     method,\n\u001b[0;32m    719\u001b[0m     url,\n\u001b[0;32m    720\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    721\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    722\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    723\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    724\u001b[0m )\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:404\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1061\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1061\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:179\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout),\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPSConnection object at 0x000001DE07AFEC00>, 'Connection to krisha.kz timed out. (connect timeout=None)')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:802\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    800\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 802\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    803\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39me, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    804\u001b[0m )\n\u001b[0;32m    805\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:594\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    596\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='krisha.kz', port=443): Max retries exceeded with url: /prodazha/kvartiry/astana/?page=295?page=1 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DE07AFEC00>, 'Connection to krisha.kz timed out. (connect timeout=None)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://krisha.kz/prodazha/kvartiry/astana/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m pipeline(base_url, \u001b[38;5;241m1000\u001b[39m)\n",
      "Cell \u001b[1;32mIn[24], line 11\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(base_url, max_pages)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ“„ Processing page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 11\u001b[0m data \u001b[38;5;241m=\u001b[39m scrape_all_apartments(url, max_pages\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# force it to scrape only this one page\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Filter out existing URLs\u001b[39;00m\n\u001b[0;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m [row \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data \u001b[38;5;28;01mif\u001b[39;00m row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m existing_urls]\n",
      "Cell \u001b[1;32mIn[17], line 7\u001b[0m, in \u001b[0;36mscrape_all_apartments\u001b[1;34m(base_url, max_pages, delay)\u001b[0m\n\u001b[0;32m      5\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching listings from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mok:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to fetch page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:688\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[1;32m--> 688\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectTimeout\u001b[0m: HTTPSConnectionPool(host='krisha.kz', port=443): Max retries exceeded with url: /prodazha/kvartiry/astana/?page=295?page=1 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DE07AFEC00>, 'Connection to krisha.kz timed out. (connect timeout=None)'))"
     ]
    }
   ],
   "source": [
    "base_url = \"https://krisha.kz/prodazha/kvartiry/astana/\"\n",
    "pipeline(base_url, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92fae2b-f5c9-4739-86ae-8f5a94b3a0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
